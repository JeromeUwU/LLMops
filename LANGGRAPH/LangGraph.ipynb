{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbot LangGraph\n"
      ],
      "metadata": {
        "id": "9K-UqobVbOoq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3PySW8tbLIu",
        "outputId": "2a15c20f-6a70-461d-b019-65f6fd644bf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.39-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.4,>=0.2.39 (from langgraph)\n",
            "  Downloading langchain_core-0.3.13-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.34-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith) (2.32.3)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4,>=0.2.39->langgraph)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Collecting httpx-sse>=0.4.0 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langsmith) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith) (2.2.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n",
            "Downloading langgraph-0.2.39-py3-none-any.whl (113 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.13-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.34-py3-none-any.whl (28 kB)\n",
            "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, httpx-sse, h11, requests-toolbelt, jsonpatch, httpcore, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.13 langgraph-0.2.39 langgraph-checkpoint-2.0.2 langgraph-sdk-0.1.34 langsmith-0.1.137 orjson-3.10.10 requests-toolbelt-1.0.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langgraph langsmith\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM-ml0efbVUp",
        "outputId": "ee179a4f-6df6-4dab-99de-5484cc4e90bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.13)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.137)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.16.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, groq, dataclasses-json, langchain-text-splitters, langchain_groq, langchain, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 groq-0.11.0 langchain-0.3.4 langchain-text-splitters-0.3.0 langchain_community-0.3.3 langchain_groq-0.2.0 marshmallow-3.23.0 mypy-extensions-1.0.0 pydantic-settings-2.6.0 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "fmaHOGi5b_ad"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = userdata.get('GROQ_API_KEY')\n",
        "langsmith_api_key = userdata.get('LANGSMITH_API_KEY')"
      ],
      "metadata": {
        "id": "BJ4NQ6QQdCTu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_API_KEY'] = langsmith_api_key\n",
        "os.environ['GROQ_API_KEY'] = groq_api_key\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_PROJECT'] = 'Langgraph_test'"
      ],
      "metadata": {
        "id": "3LHQCVLudIcg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Gemma2-9b-It\")"
      ],
      "metadata": {
        "id": "nFrWc5VOeP54"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatBot ?\n"
      ],
      "metadata": {
        "id": "l7GxQMdOelHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "ejcQ5SlvegRi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "  messages:Annotated[list,add_messages] # appending the messages to the list\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n"
      ],
      "metadata": {
        "id": "s_xGiLiZe6wy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxg31tAJfse8",
        "outputId": "a2d1f8ae-0849-41b5-ebe7-9a14ddef2012"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d30e310fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def groqchatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state['messages'])}"
      ],
      "metadata": {
        "id": "bAaNJmbbfuin"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"groqchatbot\", groqchatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22xhwOiGgMUi",
        "outputId": "9551d500-a57b-401f-8e3f-d2ce2bf2fd52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d30e310fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbYta5U4gS9o",
        "outputId": "e259ac37-8086-45c7-ac89-8b65ee4eb255"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d30e310fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START, \"groqchatbot\")\n",
        "graph_builder.add_edge(\"groqchatbot\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdvCOX06gYYv",
        "outputId": "cb86c340-ab8f-4cbb-b1aa-2fd1b6614b28"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7d30e310fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "f7xW3nb6grPb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image,display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "Yv8R5iMjgw37",
        "outputId": "ed8eb576-a339-498d-c085-6a1fc598ec54"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ux0r0ftvl6z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"User: \")\n",
        "  if user_input.lower() in ['quit','q']:\n",
        "    print(\"Bot: Goodbye!\")\n",
        "    break\n",
        "  for event in graph.stream({\"messages\":(\"user\",user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value[\"messages\"])\n",
        "      print(\"Assistant:\", value[\"messages\"].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkxqszMphJNY",
        "outputId": "9aea3e55-99d9-4233-dd2c-0e85abf03e69"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Hi\n",
            "dict_values([{'messages': AIMessage(content='Hi there! üëã \\n\\nWhat can I do for you today? üòä\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 10, 'total_tokens': 28, 'completion_time': 0.032727273, 'prompt_time': 4.4e-07, 'queue_time': 0.132904359, 'total_time': 0.032727713}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f5bfe488-ab02-40f2-95bf-239b3412de60-0', usage_metadata={'input_tokens': 10, 'output_tokens': 18, 'total_tokens': 28})}])\n",
            "content='Hi there! üëã \\n\\nWhat can I do for you today? üòä\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 10, 'total_tokens': 28, 'completion_time': 0.032727273, 'prompt_time': 4.4e-07, 'queue_time': 0.132904359, 'total_time': 0.032727713}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-f5bfe488-ab02-40f2-95bf-239b3412de60-0' usage_metadata={'input_tokens': 10, 'output_tokens': 18, 'total_tokens': 28}\n",
            "Assistant: Hi there! üëã \n",
            "\n",
            "What can I do for you today? üòä\n",
            "\n",
            "User: what is generative ai \n",
            "dict_values([{'messages': AIMessage(content='Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: \\n\\n* **Traditional AI** is great at analyzing existing data and making predictions. For example, it can tell you which movie you might like based on your past viewing history.\\n* **Generative AI** goes a step further. It learns the patterns and structures within data and then uses that knowledge to generate entirely new content that resembles the data it was trained on.\\n\\n**Here are some examples of what generative AI can do:**\\n\\n* **Write text:**\\n\\nGenerate stories, poems, articles, dialogue, and even code.\\n* **Create images:**\\n\\nProduce realistic photographs, paintings, illustrations, and other visuals.\\n* **Compose music:**\\n\\nWrite original melodies, harmonies, and even entire musical pieces.\\n* **Generate audio:**\\n\\nCreate voiceovers, sound effects, and even realistic conversations.\\n* **Design products:**\\n\\nHelp design new products, from furniture to clothing to electronics.\\n\\n**How does it work?**\\n\\nGenerative AI models are typically trained on massive datasets of existing content. They learn the underlying patterns and relationships within this data, allowing them to generate new content that follows similar rules and structures.\\n\\nSome popular generative AI models include:\\n\\n* **GPT-3 (text):** Can write stories, articles, and even code.\\n* **DALL-E 2 (images):** Creates realistic and imaginative images from text descriptions.\\n* **Midjourney (images):** Generates artistic and surreal images from text prompts.\\n* **Jukebox (audio):** Composes original music in various styles.\\n\\n**The potential of generative AI is vast:**\\n\\nIt has the power to revolutionize many industries, from creative arts and entertainment to education and healthcare.\\n\\n\\nLet me know if you have any other questions about generative AI!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 388, 'prompt_tokens': 14, 'total_tokens': 402, 'completion_time': 0.705454545, 'prompt_time': 7.9599e-05, 'queue_time': 0.014562509, 'total_time': 0.705534144}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e7bc085e-06c6-463e-992b-a5b38e9d4e30-0', usage_metadata={'input_tokens': 14, 'output_tokens': 388, 'total_tokens': 402})}])\n",
            "content='Generative AI is a type of artificial intelligence that focuses on creating new content. \\n\\nThink of it like this: \\n\\n* **Traditional AI** is great at analyzing existing data and making predictions. For example, it can tell you which movie you might like based on your past viewing history.\\n* **Generative AI** goes a step further. It learns the patterns and structures within data and then uses that knowledge to generate entirely new content that resembles the data it was trained on.\\n\\n**Here are some examples of what generative AI can do:**\\n\\n* **Write text:**\\n\\nGenerate stories, poems, articles, dialogue, and even code.\\n* **Create images:**\\n\\nProduce realistic photographs, paintings, illustrations, and other visuals.\\n* **Compose music:**\\n\\nWrite original melodies, harmonies, and even entire musical pieces.\\n* **Generate audio:**\\n\\nCreate voiceovers, sound effects, and even realistic conversations.\\n* **Design products:**\\n\\nHelp design new products, from furniture to clothing to electronics.\\n\\n**How does it work?**\\n\\nGenerative AI models are typically trained on massive datasets of existing content. They learn the underlying patterns and relationships within this data, allowing them to generate new content that follows similar rules and structures.\\n\\nSome popular generative AI models include:\\n\\n* **GPT-3 (text):** Can write stories, articles, and even code.\\n* **DALL-E 2 (images):** Creates realistic and imaginative images from text descriptions.\\n* **Midjourney (images):** Generates artistic and surreal images from text prompts.\\n* **Jukebox (audio):** Composes original music in various styles.\\n\\n**The potential of generative AI is vast:**\\n\\nIt has the power to revolutionize many industries, from creative arts and entertainment to education and healthcare.\\n\\n\\nLet me know if you have any other questions about generative AI!\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 388, 'prompt_tokens': 14, 'total_tokens': 402, 'completion_time': 0.705454545, 'prompt_time': 7.9599e-05, 'queue_time': 0.014562509, 'total_time': 0.705534144}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-e7bc085e-06c6-463e-992b-a5b38e9d4e30-0' usage_metadata={'input_tokens': 14, 'output_tokens': 388, 'total_tokens': 402}\n",
            "Assistant: Generative AI is a type of artificial intelligence that focuses on creating new content. \n",
            "\n",
            "Think of it like this: \n",
            "\n",
            "* **Traditional AI** is great at analyzing existing data and making predictions. For example, it can tell you which movie you might like based on your past viewing history.\n",
            "* **Generative AI** goes a step further. It learns the patterns and structures within data and then uses that knowledge to generate entirely new content that resembles the data it was trained on.\n",
            "\n",
            "**Here are some examples of what generative AI can do:**\n",
            "\n",
            "* **Write text:**\n",
            "\n",
            "Generate stories, poems, articles, dialogue, and even code.\n",
            "* **Create images:**\n",
            "\n",
            "Produce realistic photographs, paintings, illustrations, and other visuals.\n",
            "* **Compose music:**\n",
            "\n",
            "Write original melodies, harmonies, and even entire musical pieces.\n",
            "* **Generate audio:**\n",
            "\n",
            "Create voiceovers, sound effects, and even realistic conversations.\n",
            "* **Design products:**\n",
            "\n",
            "Help design new products, from furniture to clothing to electronics.\n",
            "\n",
            "**How does it work?**\n",
            "\n",
            "Generative AI models are typically trained on massive datasets of existing content. They learn the underlying patterns and relationships within this data, allowing them to generate new content that follows similar rules and structures.\n",
            "\n",
            "Some popular generative AI models include:\n",
            "\n",
            "* **GPT-3 (text):** Can write stories, articles, and even code.\n",
            "* **DALL-E 2 (images):** Creates realistic and imaginative images from text descriptions.\n",
            "* **Midjourney (images):** Generates artistic and surreal images from text prompts.\n",
            "* **Jukebox (audio):** Composes original music in various styles.\n",
            "\n",
            "**The potential of generative AI is vast:**\n",
            "\n",
            "It has the power to revolutionize many industries, from creative arts and entertainment to education and healthcare.\n",
            "\n",
            "\n",
            "Let me know if you have any other questions about generative AI!\n",
            "\n",
            "User: q\n",
            "Bot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yptkXV3cigFa"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}